{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtWeCKZYhI1k",
        "outputId": "9a4c25fd-3d5e-4dc3-fb4a-012542732adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vaderSentiment) (2025.1.31)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m122.9/126.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "   Unnamed: 0.1  Unnamed: 0  \\\n",
            "0             0           0   \n",
            "1             1           1   \n",
            "2             2           2   \n",
            "3             3           3   \n",
            "4             4           4   \n",
            "\n",
            "                                                Text    Sentiment  \\\n",
            "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
            "1   Traffic was terrible this morning.           ...   Negative     \n",
            "2   Just finished an amazing workout! 💪          ...   Positive     \n",
            "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
            "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
            "\n",
            "             Timestamp            User     Platform  \\\n",
            "0  2023-01-15 12:30:00   User123          Twitter     \n",
            "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
            "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
            "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
            "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
            "\n",
            "                                     Hashtags  Retweets  Likes       Country  \\\n",
            "0   #Nature #Park                                  15.0   30.0     USA         \n",
            "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
            "2   #Fitness #Workout                              20.0   40.0   USA           \n",
            "3   #Travel #Adventure                              8.0   15.0     UK          \n",
            "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
            "\n",
            "   Year  Month  Day  Hour  \n",
            "0  2023      1   15    12  \n",
            "1  2023      1   15     8  \n",
            "2  2023      1   15    15  \n",
            "3  2023      1   15    18  \n",
            "4  2023      1   15    19  \n",
            "Index(['Unnamed: 0.1', 'Unnamed: 0', 'Text', 'Sentiment', 'Timestamp', 'User',\n",
            "       'Platform', 'Hashtags', 'Retweets', 'Likes', 'Country', 'Year', 'Month',\n",
            "       'Day', 'Hour'],\n",
            "      dtype='object')\n",
            "Available columns: ['Unnamed: 0.1', 'Unnamed: 0', 'Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Retweets', 'Likes', 'Country', 'Year', 'Month', 'Day', 'Hour']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /usr/local/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /usr/local/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /usr/local/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /usr/local/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available columns: ['Unnamed: 0.1', 'Unnamed: 0', 'Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Retweets', 'Likes', 'Country', 'Year', 'Month', 'Day', 'Hour']\n",
            "                                                Text  \\\n",
            "0   Enjoying a beautiful day at the park!        ...   \n",
            "1   Traffic was terrible this morning.           ...   \n",
            "2   Just finished an amazing workout! 💪          ...   \n",
            "3   Excited about the upcoming weekend getaway!  ...   \n",
            "4   Trying out a new recipe for dinner tonight.  ...   \n",
            "\n",
            "                         clean_text  \n",
            "0       enjoying beautiful day park  \n",
            "1          traffic terrible morning  \n",
            "2          finished amazing workout  \n",
            "3  excited upcoming weekend getaway  \n",
            "4  trying new recipe dinner tonight  \n",
            "                                                Text  \\\n",
            "0   Enjoying a beautiful day at the park!        ...   \n",
            "1   Traffic was terrible this morning.           ...   \n",
            "2   Just finished an amazing workout! 💪          ...   \n",
            "3   Excited about the upcoming weekend getaway!  ...   \n",
            "4   Trying out a new recipe for dinner tonight.  ...   \n",
            "\n",
            "                         clean_text  polarity  subjectivity  vader_compound  \\\n",
            "0       enjoying beautiful day park  0.675000      0.800000          0.8074   \n",
            "1          traffic terrible morning -1.000000      1.000000         -0.4767   \n",
            "2          finished amazing workout  0.600000      0.900000          0.5859   \n",
            "3  excited upcoming weekend getaway  0.375000      0.750000          0.3400   \n",
            "4  trying new recipe dinner tonight  0.136364      0.454545          0.0000   \n",
            "\n",
            "  sentiment  \n",
            "0  Positive  \n",
            "1  Negative  \n",
            "2  Positive  \n",
            "3  Positive  \n",
            "4   Neutral  \n",
            "Accuracy: 0.7074829931972789\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.24      0.38        38\n",
            "           1       0.00      0.00      0.00        14\n",
            "           2       0.69      1.00      0.82        95\n",
            "\n",
            "    accuracy                           0.71       147\n",
            "   macro avg       0.53      0.41      0.40       147\n",
            "weighted avg       0.68      0.71      0.63       147\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 9  0 29]\n",
            " [ 1  0 13]\n",
            " [ 0  0 95]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'max_iter': 100}\n",
            "The predicted sentiment for the input text is: Negative\n"
          ]
        }
      ],
      "source": [
        "!pip install vaderSentiment\n",
        "%run /Untitled3.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TF-IDF Vectorizer: Converts the text into numerical form\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = tfidf.fit_transform(df['clean_text'])  # Uses cleaned text\n",
        "\n",
        "# Encode sentiment labels\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(df['sentiment'])  # 'Positive', 'Negative', 'Neutral'\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "KbwPdNIDhRLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Initialize model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooCdlF0phVLP",
        "outputId": "4f512927-a1d1-4e45-9618-e359ca1b0286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7278911564625851\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.37      0.50        38\n",
            "           1       1.00      0.07      0.13        14\n",
            "           2       0.72      0.97      0.83        95\n",
            "\n",
            "    accuracy                           0.73       147\n",
            "   macro avg       0.83      0.47      0.49       147\n",
            "weighted avg       0.76      0.73      0.68       147\n",
            "\n",
            "Confusion Matrix:\n",
            " [[14  0 24]\n",
            " [ 1  1 12]\n",
            " [ 3  0 92]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(new_text):\n",
        "    clean_text1 = clean_text(new_text)\n",
        "    new_text_tfidf = tfidf.transform([clean_text1])\n",
        "    sentiment_score = model.predict(new_text_tfidf)\n",
        "    sentiment_label = encoder.inverse_transform(sentiment_score)\n",
        "    return sentiment_label[0]\n",
        "\n",
        "# Example usage:\n",
        "new_input = \"I am disappointed with the service\"\n",
        "predicted_sentiment = predict_sentiment(new_input)\n",
        "print(f\"The predicted sentiment for the input text is: {predicted_sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOBvbo3ihXgW",
        "outputId": "2846d99c-d46c-40a9-91ff-959fe7c0366f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted sentiment for the input text is: Positive\n"
          ]
        }
      ]
    }
  ]
}